# -*- coding: utf-8 -*-
"""ev_database_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WM1gvkTCx-xDrkYza_AhoJBk0sNoJsfJ
"""

!pip install html-table-parser-python3
!pip install xlsxwriter

import time
#time.sleep(5)

#mounting drive
from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('/content/drive/MyDrive/codes')


# from google.colab import files
# uploaded = files.upload()

####importing csv to pandas and finally to list###########
# importing module
import pandas as pd

# reading CSV file
autourl =pd.read_csv("/content/drive/MyDrive/codes/ev_benchmark_url.csv",header=None)
ev_list=autourl[0].tolist()

#######create excel sheet##################
# import xlsxwriter module
import xlsxwriter
workbook = xlsxwriter.Workbook('ev_database.xlsx')
workbook.close()

# Library for opening url and creating
# requests
import urllib.request

# pretty-print python data structures
from pprint import pprint

# for parsing all the tables present
# on the website
from html_table_parser.parser import HTMLTableParser

# for converting the parsed data in a
# pandas dataframe
import pandas as pd


# Opens a website and read its
# binary contents (HTTP Response Body)
def url_get_contents(url):

	# Opens a website and read its
	# binary contents (HTTP Response Body)

	#making request to the website
	req = urllib.request.Request(url=url)
	f = urllib.request.urlopen(req)

	#reading contents of the website
	return f.read()
#########outide loop variable#################
data_bin=[]
out_bin=[]

###########################
#ev_list=['https://ev-database.org/car/1651/Volkswagen-ID-Buzz-Pro','https://ev-database.org/car/1240/Mercedes-EQV-300-Long']
#ev_list=['https://ev-database.org/car/1240/Mercedes-EQV-300-Long']
for j in range(0,len(ev_list)):
  # defining the html contents of a URL.
  url=ev_list[j]
  xhtml = url_get_contents(url).decode('utf-8')

  # Defining the HTMLTableParser object
  p = HTMLTableParser()

  # feeding the html contents in the
  # HTMLTableParser object
  p.feed(xhtml)

  # Now finally obtaining the data of
  # the table required
  #pprint(len(p.tables))
  ########################################
  ################################################
  out=url.split('/')[-1]
  ###removing special character with underscore######
  out= out.translate ({ord(c): "_" for c in "!@#$%^&*()[]{};:,./<>?\|`~-=_+"})
  out_bin.append(out)
  ###################################################
  ##############################################
  data=pd.DataFrame({'0': [out]})
  data=data.append(p.tables[0])
  data.reset_index(drop=True)
  for i in range(0,len(p.tables)-1):
    # print(i)
    # pprint(p.tables[i])
    # data=pd.DataFrame(p.tables[i])
    data=data.append(pd.DataFrame(p.tables[i+1]))
  data.reset_index(drop=True)

  ############reducing name to 30 characters###########
  # if(len(out)>29):
  #   out=out[0:29]
  #####################################################
  data_bin.append(data)
  
  ###################################################
  time.sleep(15)

# ############exporting into excel with units####################
# startrow = 0
# import os
# path = r"/content/drive/MyDrive/codes/ev_database.xlsx"
# writer = pd.ExcelWriter(path, engine = 'xlsxwriter')
# for k in range(0,len(data_bin)):
#   data_bin[k].to_excel(writer, sheet_name =str(k),startrow=startrow,header=False,index=False)
# writer.save()

"""**Units Remove**"""

#########exporting data without units##########
for n in range(0,len(data_bin)):
  data_bin[n].columns =['name', 'value','nothing1','nothing2','nothing3','nothing4']
  data_bin[n].value = data_bin[n].value.str.extract('(\d*\.\d+|\d+)', expand=False).astype(float)

############exporting into excel####################
startrow = 0
import os
path = r"/content/drive/MyDrive/codes/ev_database.xlsx"
writer = pd.ExcelWriter(path, engine = 'xlsxwriter')
for k in range(0,len(data_bin)):
  data_bin[k].to_excel(writer, sheet_name =str(k),startrow=startrow,header=False,index=False)
writer.save()

"""**Consolidating data**"""

listy = [[] for i in range(0,len(data_bin))]
print(listy)

ev_vardf =pd.read_csv("/content/drive/MyDrive/codes/1_Variables_EV_BENCHMARK.csv",header=None)
vari=ev_vardf[0].tolist()

# vari=["Range","Top"]
for m in vari:
  for n in range(0,len(data_bin)):
    try:
      temp=data_bin[n].loc[data_bin[n].name.str.contains(m)==True]
      if(len(temp.value)>1):
        listy[n].append("duplicate")
      else:      
        listy[n].append(temp.value.iloc[0])
    except:
      listy[n].append("NA")

print(listy)

print(vari)

df = pd.DataFrame(listy,columns=vari)
df=df.T
df.columns=out_bin

print(df)

print(vari)

df.to_excel("final.xlsx")